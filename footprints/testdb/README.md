The *testdb* directory includes the processing code to intersect hint or wellington ouptut with the FIMO database and put the results in a database. This code is in the `src` directory.

The code is an updated version of that used by examples in the `serial_examples` directory, which can be considered legacy code, and aren't actively used any more. The current workflow has been parallelized to enable faster database creation. 

Currently, the workflow is:

- [ ] Make a new folder for running each batch of data by copying all contents from a previous run to the newly created folder (such as the `skin_20` folder). This should include scripts for each footprinting method (e.g. `hint.R`,`wellington.R`), a shell script (e.g. `run_skin_20.sh`), and a `nohup.out` file. 
- [ ] Delete the `nohup.out` file from the new direcoty
- [ ] Rename the shell script and edit it to replace its databases with your new database names
- [ ] Add the new databases to [src/dbFunctions.R](https://github.com/PriceLab/BDDS/blob/master/footprints/testdb/src/dbFunctions.R)
- [ ] Alter the file paths, database names, and IDs in the master scripts (`hint.R`, `wellington.R`, etc.) 
- [ ] Run the shell script using the nohup option to collect output
- [ ] Check database contents
- [ ] Make database read only

As a concrete example, here's how to build a database from the hint and wellington output generated by running the [makefile-based tests](https://github.com/PriceLab/BDDS/tree/master/footprints/functionalTests) (e.g. `make hint PYTHON=3` and `make wellington PYTHON=3`).

- [ ] **Make a new folder** by copying from a previous run

From the `BDDS/footprints/testdb` directory:

```
cp -r skin_20 test_dbs
```

Now we have a new folder containing our 2 master scripts (`hint.R` and `wellington.R`), our shell script (`run_skin_20.sh`), and the output from the previous run (`nohup.out`)

- [ ] **Delete the `nohup.out` file**

The `nohup.out` file is a record of the previous run; each run of a `run_<name>.sh` script generates its own `nohup.out` file, thus you should delete the existing one:

```
rm test_dbs/nohup.out
```

- [ ] **Rename and edit the shell script** 

The shell script carries out two functions: 

- Creating the new databases and their tables
- Running the master scripts

In order to create the proper databases and run the proper scripts, it's vital to replace the existing database and file path names with your new ones. For our test case, that means the following substitutions:

**Current up to here**

make the following changes in exampleRun/hint.R:

line | original | new
---- | -------- | ---
line 21 | was: `hint.path <- "/local/lymphoblast/hint"` | now `hint.path <- "/local/Ben/BDDS/footprints/functionalTests/output/hint"`
line 33 | was `db.hint <- getDBConnection("lymphoblast_hint_whovian")` | now `db.hint <- getDBConnection("testhint_whovian")`
line 48 | was `chromosomes <- paste("chr", c(13), sep="")` | now `chromosomes <- paste("chr", c(19), sep="")`
line 53 | was `minid = "lymphoblast.filler.minid",` | now `minid = "testexample.filler.minid",`
line 56 | was `dbTable = "lymphoblast_hint",` | now `dbTable = "testhint",`

similarly, exampleRun/wellington.R should be edited to point to the testwellington_whovian database (edit the same lines in wellington.R)

then the scripts can be run with `R -f hint.R` and `R -f wellington.R`

- [ ] **Create database** (this assumes that the psql database and users have been set up as described in [initDB.sql](https://github.com/PriceLab/BDDS/blob/master/footprints/testdb/dbInitialization/initDB.sql)) (this step is also described in [createTestHint.sql](https://github.com/PriceLab/BDDS/blob/master/footprints/testdb/dbInitialization/createTestHint.sql))
```
psql -U databasemaker -h whovian
create database testwellington;
grant all privileges on database testwellington to trena;
create database testhint;
grant all privileges on database testhint to trena;
\q

psql testwellington -U trena -h whovian
create table regions(loc varchar primary key,
                     chrom varchar,
                     start int,
                     endpos int);

grant all on table "regions" to trena;

create table hits(loc varchar,
                  type varchar,
                  name varchar,
                  length int,
                  strand char(1),
                  sample_id varchar,
                  method varchar,
                  provenance varchar,
                  score1 real,
                  score2 real,
                  score3 real,
                  score4 real,
                  score5 real,
                  score6 real);

grant all on table "hits" to trena;

\connect testhint;

create table regions(loc varchar primary key,
                     chrom varchar,
                     start int,
                     endpos int);

grant all on table "regions" to trena;

create table hits(loc varchar,
                  type varchar,
                  name varchar,
                  length int,
                  strand char(1),
                  sample_id varchar,
                  method varchar,
                  provenance varchar,
                  score1 real,
                  score2 real,
                  score3 real,
                  score4 real,
                  score5 real,
                  score6 real);

grant all on table "hits" to trena;

\q
```

- [ ] **add the new databases to [src/dbFunctions.R](https://github.com/PriceLab/BDDS/blob/master/footprints/testdb/src/dbFunctions.R)**
```
} else if (database == "testwellington_whovian") {
    user= "trena"
    password="trena"
    dbname="testwellington"
    host="whovian"

} else if (database == "testhint_whovian") {
    user= "trena"
    password="trena"
    dbname="testhint"
    host="whovian"
}
```
- [ ] make a new folder for running each batch of data
this folder should be in the <root>/testdb directory (e.g. *lymphoblast*, *skin*, and *brain*)

- [ ] **copy the `hint.R` and `wellington.R` master scripts** to the newly created folder from a previous run (such as the `lymphoblast` folder)
```
cd <root>/testdb
cp -r lymphoblast exampleRun
```

- [ ] **process the data** using the master scripts (in R) to fill the database

make the following changes in exampleRun/hint.R:

line | original | new
---- | -------- | ---
line 21 | was: `hint.path <- "/local/lymphoblast/hint"` | now `hint.path <- "/local/Ben/BDDS/footprints/functionalTests/output/hint"`
line 33 | was `db.hint <- getDBConnection("lymphoblast_hint_whovian")` | now `db.hint <- getDBConnection("testhint_whovian")`
line 48 | was `chromosomes <- paste("chr", c(13), sep="")` | now `chromosomes <- paste("chr", c(19), sep="")`
line 53 | was `minid = "lymphoblast.filler.minid",` | now `minid = "testexample.filler.minid",`
line 56 | was `dbTable = "lymphoblast_hint",` | now `dbTable = "testhint",`

similarly, exampleRun/wellington.R should be edited to point to the testwellington_whovian database (edit the same lines in wellington.R)

then the scripts can be run with `R -f hint.R` and `R -f wellington.R`

- [ ] **check database contents**
```
psql testwellington -U trena -h whovian
select * from hits limit 10;
select * from regions limit 10;

\connect testhint
select * from hits limit 10;
select * from regions limit 10;
\q
```

- [ ] **index the databases**
```
psql testwellington -U trena -h whovian
create index regions_index on regions (loc, start, endpos);
create index hits_index on hits (loc);

\connect testhint
create index regions_index on regions (loc, start, endpos);
create index hits_index on hits (loc);

\q
```

- [ ] **make database read only**
```
psql testwellington -U trena -h whovian
revoke insert, update, delete, truncate on hits from public;
revoke insert, update, delete, truncate on hits from trena;

\connect testhint
revoke insert, update, delete, truncate on hits from public;
revoke insert, update, delete, truncate on hits from trena;

\q
```
