The *testdb* directory includes the processing code to intersect hint or wellington ouptut with the FIMO database and put the results in a database. This code is in the `src` directory.

The code is an updated version of that used by examples in the `serial_examples` directory, which can be considered legacy code, and aren't actively used any more. The current workflow has been parallelized to enable faster database creation. 

Currently, the workflow is:

- [ ] Make a new folder for running each batch of data by copying all contents from a previous run to the newly created folder (such as the `skin_20` folder). This should include scripts for each footprinting method (e.g. `hint.R`,`wellington.R`), a shell script (e.g. `run_skin_20.sh`), and a `nohup.out` file. 
- [ ] Delete the `nohup.out` file from the new directory
- [ ] Rename the shell script and edit it to replace its databases with your new database names
- [ ] Add the new databases to [src/dbFunctions.R](https://github.com/PriceLab/BDDS/blob/master/footprints/testdb/src/dbFunctions.R)
- [ ] Add your footprint files
- [ ] Alter the file paths, database names, and IDs in the master scripts (`hint.R`, `wellington.R`, etc.) 
- [ ] Run the shell script using the nohup option to collect output
- [ ] Check database contents
- [ ] Make database read only

As a concrete example, here's how to build a database from the hint and wellington output generated by running the [makefile-based tests](https://github.com/PriceLab/BDDS/tree/master/footprints/functionalTests) (e.g. `make hint PYTHON=3` and `make wellington PYTHON=3`).

- [ ] **Make a new folder** by copying from a previous run

From the `BDDS/footprints/testdb` directory:

```
cp -r skin_20 test_dbs
```

Now we have a new folder containing our 2 master scripts (`hint.R` and `wellington.R`), our shell script (`run_skin_20.sh`), and the output from the previous run (`nohup.out`)

- [ ] **Delete the `nohup.out` file**

The `nohup.out` file is a record of the previous run; each run of a `run_<name>.sh` script generates its own `nohup.out` file, thus you should delete the existing one:

```
rm test_dbs/nohup.out
```

- [ ] **Rename and edit the shell script** 

The shell script carries out two functions: 

- Creating the new databases and their tables
- Running the master scripts

In order to create the proper databases and run the proper scripts, it's vital to replace the existing database and file path names with your new ones. For our test case, that means the following substitutions:

line | original | new
---- | -------- | ---
line 6 | was: `create database skin_wellington_20;` | now `create database test_wellington;`
line 7 | was: `grant all privileges on database skin_wellington_20 to trena;` | now `grant all privileges on database test_wellington to trena;`
line 8 | was: `create database skin_hint_20;` | now `create database test_hint;`
line 9 | was: `grant all privileges on database skin_hint_20 to trena;` | now `grant all privileges on database test_hint to trena;`
line 11 | was `\connect skin_wellington_20` | now `\connect test_wellington`
line 37 | was `\connect skin_hint_20` | now `\connect test_hint`
line 65 | was `cd /scratch/github/BDDS/footprints/testdb/skin_20` | now `cd /scratch/github/BDDS/footprints/testdb/test_dbs`

Save the changes in this script; you don't **need** to rename it, but it is highly recommended for clarity. In this case, we'll rename it to `run_test.sh`

- [ ] **Add the new databases to [src/dbFunctions.R](https://github.com/PriceLab/BDDS/blob/master/footprints/testdb/src/dbFunctions.R)**

Following the existing format in the file, add databases of the same name, using "localhost" as the host if you're running on the same machine as the databases:

```
} else if (database == "test_wellington_localhost") {
    user= "trena"
    password="trena"
    dbname="test_wellington"
    host="localhost"

} else if (database == "test_hint_localhost") {
    user= "trena"
    password="trena"
    dbname="test_hint"
    host="localhost"
}
```

Note that the `"database"` variable is simply a string name, not a parameter used in the database connection. It is crucial that the 4 parameters match your database connection. In the above case, we're using the user `trena` with password `trena` on the `test_wellington` and `test_hint` databases, both of which are on the local machine. 

- [ ] Add your footprint files

In order to perform the intersection of the fimo databasae and the hint/wellington/piq footprints, you'll need the footprint files. A sampling of these files, for seeds 16 and 20 of brain/lymphoblash/skin and the HINT/WELLINGTON methods, can be grabbed from Amazon S3 and copied into your directory (normally /scratch/data/footprints on an EC2 instance):

`aws s3 cp s3://marichards/footprints . --recursive`

In any case, be sure that all your footprints end with `.bed`, all lowercase, else the scripts won't work properly. 

**Current to here**

- [ ] Alter the file paths, database names, and IDs in the master scripts (`hint.R`, `wellington.R`, etc.) 

In your project directory, change the paths, names, and IDs that point to your footprints, databases, and other relevant variables. For example, I will make the following changes in hint.R:

line | original | new
---- | -------- | ---
line 12 | was: `data.path <- "/scratch/data/test_set/brain_hint_20"` | now `hint.path <- "/scratch/github/BDDS/footprints/functionalTests/output/hint"`
line 17 | was `db.hint <- "brain_hint_20_localhost"` | now `db.hint <- "test_hint_localhost"`
line 53 | was `minid = "brain_hint_20.minid",` | now `minid = "testexample.filler.minid",`
line 56 | was `dbTable = "brain_hint_20",` | now `dbTable = "test_hint",`

Similarly, the wellington.R should be edited to point to the test_wellington_localhost database and the correct data path (edit the same lines in wellington.R).

- [ ] Run the shell script using the nohup option to collect output

From your project directory (in this case, the `test_dbs` directory) with your master scripts, run the shell script:

```
nohup run_test.sh
```

- [ ] **Check database contents**
```
psql test_wellington -U trena -h whovian
select * from hits limit 10;
select * from regions limit 10;

\connect test_hint
select * from hits limit 10;
select * from regions limit 10;
\q
```

- [ ] **Make database read only**
```
psql testwellington -U trena -h whovian
revoke insert, update, delete, truncate on hits from public;
revoke insert, update, delete, truncate on hits from trena;

\connect testhint
revoke insert, update, delete, truncate on hits from public;
revoke insert, update, delete, truncate on hits from trena;

\q
```
